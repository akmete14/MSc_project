Many modules are hidden in this stack. Use "module --show_hidden spider SOFTWARE" if you are not able to find the required software

The following have been reloaded with a version change:
  1) stack/.2024-04-silent => stack/2024-04


----------------------------------------------------------------------------
  gcc: gcc/8.5.0
----------------------------------------------------------------------------

    You will need to load all module(s) on any one of the lines below before the "gcc/8.5.0" module is available to load.

      stack/.2024-04-silent
      stack/2024-04
 
    Help:
      The GNU Compiler Collection includes front ends for C, C++, Objective-C,
      Fortran, Ada, and Go, as well as libraries for these languages.


 

23426551 5856786    Unnamed: 0           GPP  ...  IGBP_veg_short_b'WET'  IGBP_veg_short_b'CVM'
0           0 -2.190074e-08  ...                    NaN                    NaN
1           1 -2.026436e-08  ...                    NaN                    NaN
2           2 -2.037174e-08  ...                    NaN                    NaN
3           3 -1.944209e-08  ...                    NaN                    NaN
4           4 -1.816712e-08  ...                    NaN                    NaN

[5 rows x 29 columns]    Unnamed: 0           GPP  ...  IGBP_veg_short_b'WET'  IGBP_veg_short_b'CVM'
0       16297 -9.148815e-09  ...                    NaN                    NaN
1       16298 -1.185117e-08  ...                    NaN                    NaN
2       16299 -1.204643e-08  ...                    NaN                    NaN
3       16300 -1.109531e-08  ...                    NaN                    NaN
4       16301 -1.365915e-08  ...                    NaN                    NaN

[5 rows x 29 columns] Index(['Unnamed: 0', 'GPP', 'Tair', 'vpd', 'SWdown', 'LWdown',
       'SWdown_clearsky', 'LST_TERRA_Day', 'LST_TERRA_Night', 'EVI', 'NIRv',
       'NDWI_band7', 'LAI', 'fPAR', 'hour', 'IGBP_veg_short_b'MF'', 'site_id',
       'cluster', 'IGBP_veg_short_b'GRA'', 'IGBP_veg_short_b'ENF'',
       'IGBP_veg_short_b'SAV'', 'IGBP_veg_short_b'EBF'',
       'IGBP_veg_short_b'WSA'', 'IGBP_veg_short_b'DBF'',
       'IGBP_veg_short_b'OSH'', 'IGBP_veg_short_b'CRO'',
       'IGBP_veg_short_b'CSH'', 'IGBP_veg_short_b'WET'',
       'IGBP_veg_short_b'CVM''],
      dtype='object')
  0%|          | 0/25 [00:00<?, ?it/s] 20%|██        | 5/25 [00:00<00:00, 40.79it/s] 40%|████      | 10/25 [00:00<00:00, 36.28it/s] 60%|██████    | 15/25 [00:00<00:00, 37.87it/s] 76%|███████▌  | 19/25 [00:00<00:00, 38.25it/s] 96%|█████████▌| 24/25 [00:00<00:00, 39.14it/s]100%|██████████| 25/25 [00:00<00:00, 38.15it/s]
  0%|          | 0/25 [00:00<?, ?it/s] 52%|█████▏    | 13/25 [00:00<00:00, 121.53it/s]100%|██████████| 25/25 [00:00<00:00, 128.64it/s]
reduced to float32
now start scaling
scaled
[18:17:31] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.
model fitted
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:07<01:08,  7.66s/it] 20%|██        | 2/10 [00:12<00:45,  5.72s/it] 30%|███       | 3/10 [00:16<00:36,  5.18s/it] 40%|████      | 4/10 [00:21<00:31,  5.17s/it] 50%|█████     | 5/10 [00:25<00:23,  4.69s/it] 60%|██████    | 6/10 [00:31<00:21,  5.27s/it] 70%|███████   | 7/10 [00:38<00:16,  5.56s/it] 80%|████████  | 8/10 [00:49<00:14,  7.34s/it] 90%|█████████ | 9/10 [00:53<00:06,  6.51s/it]100%|██████████| 10/10 [00:59<00:00,  6.31s/it]100%|██████████| 10/10 [00:59<00:00,  5.98s/it]
Evaluation Metrics by Cluster:
   cluster       mse        r2  num_samples
0        0  0.000304  0.734145       830631
1        1  0.000315  0.718212       442086
2        2  0.000206  0.779821       362958
3        3  0.000372  0.763954       363193
4        4  0.000167  0.837730       318458
5        5  0.000461  0.762371       990018
6        6  0.000374  0.731875       776366
7        7  0.000060  0.661921       707263
8        8  0.000379  0.746056       379925
9        9  0.000292  0.779763       685888
